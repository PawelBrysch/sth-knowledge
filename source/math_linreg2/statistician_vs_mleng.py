Ucząc się statystyki nachodzą mnie czasem różne olśnienia. Zwykle mówię je bliskiej osobie i to mi wystarcza. Tym razem przewidywana przeze mnie wielkość olśnienia jest tak duża, że postanowiłem się nią podzielić na forum. Przechodzę do rzeczy.
Zauważyłem pewien konflikt, który istnieje pomiędzy statystykami, a programistami implementującymi modele statystyczne (nazwijmy ich w skrócie "ML engineerami").

*Statystycy często sprawdzają, jak bliskie prawdy są ich modele. Na efekty pracy ML engineerów mówią: "garbage in, garbage out".

*ML engineerowie  z kolei mają często w nosie statystykę. Ważne, że model działa.

Do tej pory byłem bezstronny w tym sporze, jednak widzę przesłanki, by przystać do ML engineerów. Już tłumaczę dlaczego.
Statystycy żyją w przeświadczeniu, że ich dane to tylko wycinek większej całości, więc muszą nieustanie sprawdzać poziomy istotności.
Co jednak w przypadku, gdy wraz z rozwojem technologii nie musimy mieć już do czynienia z wycinkami całości, a z ... całością ? (= Big Data)